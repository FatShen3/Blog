---
title: æœºå™¨å­¦ä¹ -KNN
tags:
  - æœºå™¨å­¦ä¹ 
  - python
categories:
  - æœºå™¨å­¦ä¹ 
mathjax: true
date: 2018-04-05 15:30:34
---


ç”Ÿå‘½åœ¨äºæŠ˜è…¾ï¼Œæœ€è¿‘å…¥å‘æœºå™¨å­¦ä¹ ï¼ŒæŠŠpythonè£…å¥½ï¼Œä¹ŸæŠŠè¯­æ³•å’Œç‰¹æ€§å¤§è‡´è¿‡äº†ä¸€éã€‚çœ‹äº†ä¸‹éƒ½æ¯”è¾ƒæ¨èæ–¯å¦ç¦çš„cs231nï¼Œæ‰€ä»¥å°±å†³å®šå­¦ä¹ å®ƒæ¥ä½œä¸ºå…¥å‘é€šé“äº†ğŸ˜„ã€‚

<!--more-->

## å®‰è£…ç¯å¢ƒ

### python

python3å’Œpython2åŒºåˆ«è¿˜æ˜¯å¾ˆå¤§çš„ï¼Œå’±è¿˜æ˜¯ç”¨æœ€æ–°çš„å§

```bash
brew install python3
```

### sklearn

è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„æœºå™¨å­¦ä¹ åº“ï¼Œç›¸æ¯”èµ·æ¥tensorflowåº”è¯¥æ›´åå‘å®šä½äºæ·±åº¦å­¦ä¹ ï¼Œä¸€æ­¥ä¸€æ­¥æ¥å°±å…ˆæŠŠè¿™ä¸ªè£…äº†å§

```bash
python3 -m pip install scikit-learn
```

### numpy

ä¸€ä¸ªpythonçš„ç§‘å­¦è®¡ç®—çš„åŸºç¡€åº“ï¼Œæä¾›äº†å¤šç»´æ•°ç»„å’ŒçŸ©é˜µçš„è¿ç®—ã€‚

```bash
python3 -m pip install numpy
```

### matplotlib

åŸºäºpythonçš„2Dç»˜å›¾åº“ã€‚

```bash
python3 -m pip install matplotlib
```

### debug

ç›®å‰ç”¨çš„IDEæ˜¯vs code, å·²ç»æœ‰æ’ä»¶æ”¯æŒpythonã€‚è£…å¥½æ’ä»¶åï¼Œé…ä¸Špython3çš„æ‰§è¡Œç¯å¢ƒä»¥åŠlintç­‰è·¯å¾„åï¼Œæˆ‘éšä¾¿æ‰¾äº†ä¸ªä¾‹å­ä¸€è·‘å‘ç°numpyæœ‰ä¸ªåœ°æ–¹ä¸å¯¹åŠ²ã€‚function_base.py(line 4533)åœ¨import numpyçš„æ—¶å€™ä¼šæŠ›å‡ºAttributeErrorå’ŒRuntimeError, ç„¶åå®ƒç›´æ¥except Exceptionï¼Œæ¯æ¬¡ä¸€debugå°±ä¼šå…ˆåœ¨é‚£é‡Œåœä¸ªnå¤šæ¬¡(è°ƒè¯•æ¨¡å¼æ‰“å¼€äº†stop at uncaught exception)ï¼Œéš¾é“çˆ¶ç±»Exceptionä¸è¡Œ? æœºåˆ¶çš„æˆ‘ç«‹é©¬æƒ³åˆ°é‚£æˆ‘ç»™exceptäº†å§ã€‚

```diff
+	except (AttributeError, RuntimeError):
+        # ä¸ºäº†vscodeåˆ«åœåœ¨è¿™é‡Œï¼Œå½“ç„¶ä¿®æ”¹launch.jsonä¹Ÿè¡Œ...ä¸è¿‡é‚£æ ·å°±ç›´æ¥é’ˆå¯¹å…¨éƒ¨ç”Ÿæ•ˆäº†, ä½†æ˜¯æ²¡ç”¨å‘¢ï¼
+        print('catch this err just to avoid vscode stop at uncaught exception')
    except Exception:
        pass
```

ä¿®æ”¹äº†ä»£ç åå‘ç°ç«Ÿç„¶æ²¡æœ‰ç”¨, è·‘åˆ°æ’ä»¶githubä¸Šçœ‹ï¼Œå‘ç°å¾ˆå¤šäººç»™å‡ºçš„æ–¹æ¡ˆæ˜¯åœ¨lanugh.jsonæ–‡ä»¶é‡ŒåŠ ä¸Šä¸‹é¢ä¸€å¥è¯å¿½ç•¥å¼‚å¸¸

```json
"exceptionHandling": {
	"ignore": ["AttributeError", "RuntimeError"]
}
```
è™½ç„¶æœ‰ç”¨ï¼Œæˆ‘è§‰å¾—è¿™æ ·ä¿®æ”¹å…¨å±€ä¹Ÿä¸å¥½ï¼Œæ‰€ä»¥å…ˆæš‚æ—¶å–æ¶ˆäº†uncaught exceptionåŠŸèƒ½ã€‚

## å¼€å§‹Hello World

Kæœ€è¿‘é‚»(k-Nearest Neighborï¼ŒKNN)åˆ†ç±»ç®—æ³•ï¼Œæ˜¯æœ€ç®€å•çš„æœºå™¨å­¦ä¹ ç®—æ³•ä¹‹ä¸€ã€‚å®ƒçš„ç†å¿µå°±æ˜¯ï¼šç»™å®šä¸€ä¸ªæ•°æ®é›†ï¼Œå¯¹äºæ–°çš„è¾“å…¥å®ä¾‹ï¼Œæ‰¾åˆ°ä¸è¯¥å®ä¾‹æœ€é‚»è¿‘çš„kä¸ªå®ä¾‹ï¼Œæœä»è¿™kä¸ªå®ä¾‹å±äºæœ€å¤šçš„é‚£ä¸ªç±»ã€‚æ‰€ä»¥å¾ˆæ˜æ˜¾çš„ï¼Œè¿™ä¸ªç®—æ³•æ˜¯ä¸€ä¸ªlazy-learningç®—æ³•ï¼Œå®ƒå¹¶ä¸è®­ç»ƒ(åªæ˜¯å‚¨å­˜è®­ç»ƒæ•°æ®)ï¼Œåœ¨åˆ†ç±»æ—¶è€—æ—¶ã€‚æ­¤å¤–ï¼Œå½“æ•°æ®é›†æ˜¯è¿ç»­çš„æ—¶å€™ï¼Œè¿˜å¯ä»¥ç”¨æ¥åšå›å½’ã€‚æ˜¾è€Œæ˜“è§ï¼Œkå€¼çš„é€‰å–ä»¥åŠè·ç¦»å‡½æ•°ï¼Œæ˜¯å½±å“ç»“æœçš„ä¸¤ä¸ªé‡è¦å› ç´ ã€‚

### ä¸€äº›æ¦‚å¿µ

#### é—µå¯å¤«æ–¯åŸºåº¦é‡(Minkowski metric)

åœ¨sklearnçš„knnä¸­é»˜è®¤çš„è·ç¦»åº¦é‡æ ‡å‡†ï¼Œåœ¨ç©ºé—´$\mathbb{R}^n$ç»™å®šä¸¤ä¸ªç‚¹aå’Œb:
		
$$X(x_{1}, x_{2}, ..., x_{n})\quad And\quad Y(y_{1}, y_{2}, ..., y_{n}) \in\mathbb{R}^n $$

è¿™ä¸¤ä¸ªç‚¹çš„ä¹‹é—´çš„é—µæ°è·ç¦»ä¸º:

$$D(X,Y) = \left(\sum_{i=1}^n|x_i-y_i|^{p}\right)^{\frac{1}{p}}$$

å½“$p = 1$æ—¶, å³ä¸ºæ›¼å“ˆé¡¿è·ç¦»(Manhattan distance):

$$D(X,Y) = \sum_{i=1}^n|x_i-y_i|$$

å½“$p = 2$æ—¶ï¼Œå³ä¸ºæ¬§å‡ é‡Œå¾—è·ç¦»(Euclidean distance):

$$D(X,Y) = \sqrt[2]{\sum_{i=1}^n|x_i-y_i|^{2}}$$

ä¹‹åçš„ä¾‹å­ä¸­æˆ‘ä»¬é‡‡ç”¨$p = 2$æ¥è®¡ç®—è·ç¦»ã€‚

#### sk-learnä¸­knnæœ€è¿‘è·ç¦»ç®—æ³•

* brute: æš´åŠ›è®¡ç®—, å¯¹äºDç»´åº¦ä¸‹çš„Nä¸ªæ•°æ®ï¼Œå…¶å¤æ‚åº¦é«˜è¾¾$O(DN^2)$
* kd_tree: kdæ ‘, æ˜¯ä¸€é¢—äºŒå‰æ ‘ï¼Œå®ƒæ ¹æ®åˆ‡åˆ†è½´ä¸­å€¼åˆ‡åˆ†æ„é€ æ ‘ï¼Œå…¶æœ¬è´¨å°±æ˜¯ï¼Œå¦‚æœAç‚¹ç¦»Bç‚¹å¾ˆè¿œï¼ŒBç‚¹ç¦»Cç‚¹å¾ˆè¿‘ï¼Œé‚£ä¹ˆAç‚¹ç¦»Cç‚¹ä¹Ÿå¾ˆè¿œï¼Œå…¶å¤æ‚åº¦å¯ä»¥é™ä½åˆ°$O(DNlogN)$ã€‚ä½†æ˜¯å½“$D >= 20$åï¼Œkdæ ‘æ•ˆç‡å°†å˜ä½ã€‚è¿™é‡Œæœ‰ä¸€ç¯‡æ–‡ç« è®²è§£çš„å¾ˆæ¸…æ¥š([ä¼ é€é—¨](https://www.joinquant.com/post/2843?f=zh))
* ball_tree: ä¸ºäº†è§£å†³ KD æ ‘åœ¨é«˜ç»´ä¸Šæ•ˆç‡ä½ä¸‹çš„é—®é¢˜

å…³äºç®—æ³•æ—¶é—´å¤æ‚åº¦ä»¥åŠå¦‚ä½•æ ¹æ®kå’Œé€‰æ‹©çš„è¯´æ˜ï¼Œsklearnå®˜ç½‘æœ‰æ›´å¤šä»‹ç»([ä¼ é€é—¨](http://scikit-learn.org/stable/modules/neighbors.html#neighbors))

#### numpy

numpyçš„ä¸»è¦å¯¹è±¡ndarray, æ˜¯ä¸€ä¸ªåŒç±»å‹å…ƒç´ çš„å¤šç»´æ•°ç»„(homogeneous multidimensional array)ã€‚åœ¨numpyä¸­, dimensions(ç»´åº¦)ä¹Ÿç§°ä¸ºaxes(è½´)ã€‚

* ä¸¾ä¸ªæ —å­: 

  [1,2]è¿™ä¸ªæ•°ç»„åªæœ‰ä¸€ä¸ªaxisï¼Œè¿™ä¸ªaxisæœ‰ä¸¤ä¸ªå…ƒç´ ï¼Œæ‰€ä»¥æˆ‘ä»¬è¯´è¿™ä¸ªaxisé•¿åº¦ä¸º2.
  
* å†ä¸¾ä¸ªæ —å­:

  [[1,2,3],[4,5,6]]è¿™ä¸ªæ•°ç»„ï¼Œå®ƒæœ‰ä¸¤ä¸ªaxesï¼Œç¬¬ä¸€ä¸ªaxisçš„é•¿åº¦ä¸º2ï¼Œç¬¬äºŒä¸ªaxisçš„é•¿åº¦ä¸º3ï¼Œæˆ‘ä»¬å¯ä»¥ç†è§£å…¶ä¸ºä¸€ä¸ª2 * 3çš„æ•°ç»„ã€‚
  
æ¥ç€ä¸Šé¢çš„è¯´ï¼Œndarrayè¿˜æœ‰ä¸€ä¸ªé‡è¦çš„å±æ€§ä¹Ÿå°±æ˜¯shape, æ˜¯ä¸€ä¸ªè¡¨æ˜æ•°ç»„åœ¨å„ä¸ªdimensionä¸Šé•¿åº¦çš„å…ƒç»„ã€‚æ¯”å¦‚ä¸Šé¢ä¸¤ä¸ªæ —å­ä¸­ï¼Œå…¶shapeåˆ†åˆ«ä¸º(2,)å’Œ(3,2)

### knnåˆ†ç±»

ä¸‹é¢ç”¨irisæ•°æ®é›†[^1]æ¥æ¨¡æ‹Ÿä¸€æ¬¡knnåˆ†ç±»ã€‚è™½ç„¶irisæ•°æ®é›†å…¶å®æ˜¯ä¸€ä¸ªshape(150,4)çš„æ•°æ®é›†ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸ºäº†æ–¹ä¾¿ç›´æ¥é˜‰å‰²åˆ°shape(150,2), æ­¤å¤–æ¯ä¸ªç‚¹çš„æƒé‡ä¹Ÿåˆ†ä¸ºäº†ä¸¤ç§ï¼ˆåŒæƒé‡æˆ–è·ç¦»æƒé‡)ã€‚ä»£ç å¦‚ä¸‹

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn import neighbors, datasets

n_neighbors = 15 # kä¸º15

iris = datasets.load_iris() # irisæ•°æ®é›† shape(150,4)

X = iris.data[:, :2] # ä¿®æ”¹ä¸ºshape(150, 2), æ–¹ä¾¿åœ¨2ç»´å›¾åƒä¸Šå±•ç¤ºæ’’
y = iris.target # irisæ•°æ®é›†çš„åˆ†ç±», åˆ†ä¸º3ç±»

h = .02  # ä¸‹é¢é¢„æµ‹ç”¨çš„äºŒç»´ç½‘æ ¼åæ ‡ç‚¹é—´éš”

cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF']) # é¢„æµ‹ç‚¹ä¸‰ä¸ªåˆ†ç±»é¢œè‰²
cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF']) # è®­ç»ƒé›†ä¸‰ä¸ªåˆ†ç±»é¢œè‰²ï¼ˆçº¯æ·±è‰²)

for i, weights in enumerate(['uniform', 'distance']): # ç»Ÿä¸€æƒé‡æˆ–è€…æŒ‰è·ç¦»çš„å€’æ•°ä½œä¸ºæƒé‡

    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
    clf.fit(X, y) # æ‹Ÿåˆ

    # å‡†å¤‡è¾¹ç•Œ[x_min, x_max] * [y_min, y_max]çš„æ–¹å½¢
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h)) # ç”Ÿæˆå¯¹åº”2ç»´æ•°æ®ç½‘æ ¼åæ ‡, hä¸ºæ¯ä¸ªç‚¹x,yè½´çš„é—´éš”

    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) # c_ ç­‰åŒäº np.r_['-1,2,0', index expression]
    Z = Z.reshape(xx.shape) # reshapeåˆ°meshgridç”Ÿæˆçš„ç½‘æ ¼çš„shape
    plt.subplot(2, 1, i + 1)
    plt.pcolormesh(xx, yy, Z, cmap=cmap_light) # å¹³é¢åŒºåŸŸé¢„æµ‹é¢œè‰²

    # Plot also the training points
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,
                edgecolor='k', s=20) # è®­ç»ƒé›†ç‚¹çš„é›†åˆ
    plt.xlim(xx.min(), xx.max()) # è®¾ç½®xï¼Œyè½´è¾¹ç¼˜
    plt.ylim(yy.min(), yy.max())
    plt.title("3-Class classification (k = %i, weights = '%s')"
              % (n_neighbors, weights))

plt.show()
```
ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤º:

{% asset_img knn-classfication.png %}

ä»ç»“æœæˆ‘ä»¬å…¶å®å¯ä»¥çœ‹å‡ºæ¥ï¼Œuniformå’Œdistanceä¸¤ç§æ¨¡å¼å¾—åˆ°çš„åŒºåŸŸç»“æœæ˜¯æœ‰å·®å¼‚çš„ï¼Œæ˜¾ç„¶æ˜¯ç”±äºé‚»è¿‘ç‚¹ç‚¹æƒé‡ä¸åŒå¼•èµ·çš„ã€‚

### knnå›å½’

å½“æ•°æ®é›†æ˜¯è¿ç»­çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åˆ©ç”¨knnæ¥åšregressionã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç”¨knnå›å½’æ¥åšæ­£å¼¦å‡½æ•°é¢„æµ‹çš„ä¾‹å­ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn import neighbors

np.random.seed(0) #è®¾ç½®ä¸ªç§å­
X = np.sort(5 * np.random.rand(50, 1), axis=0) # æµ‹è¯•é›†, ç”Ÿæˆshape(50, 1)çš„2d array, ç„¶åæ”¾å¤§5å€æ’åºç¬¬ä¸€ä¸ªæ•°è½´

T = np.linspace(0, 5, 500)[:, np.newaxis] # é¢„æµ‹é›†, 0åˆ°5ä¸­ç­‰è·ç¦»å–500ä¸ªå€¼, ç„¶åæ·»åŠ æ–°ç»´åº¦å˜æˆshape(500, 1)

y = np.sin(X).ravel() # ä¸ºxä¸­çš„å€¼å–sinå€¼ï¼Œç„¶åé™ç»´

yT = np.sin(T).ravel() # é¢„æµ‹é›†åº”è¯¥çš„çœŸå®å€¼

n_neighbors = 5 # kä¸º5

for i, weights in enumerate(['uniform', 'distance']): # distanceçš„æƒ…å†µä¸‹, è·ç¦»ä¼šæœ‰æƒé‡æ•ˆåº”
    knn = neighbors.KNeighborsRegressor(n_neighbors, weights)
    y_ = knn.fit(X, y).predict(T)
    plt.subplot(2, 1, i + 1) # ç”»ä¸ªå­plot
    plt.scatter(X, y, c='k', label='data', marker=".") # æµ‹è¯•é›†, é»‘è‰²ç‚¹
    plt.plot(T, y_, c='g', label='prediction') # ç»¿è‰²é¢„æµ‹çº¿æ¡
    plt.plot(T, yT, c='y', label='real') # çœŸå®å€¼åº”è¯¥çš„çº¿æ¡
    plt.axis('tight')
    plt.legend()
    plt.title("KNeighborsRegressor (k = %i, weights = '%s')" % (n_neighbors,
                                                                weights))

plt.show()
```
ç»“æœå¦‚ä¸‹å›¾ï¼š

{% asset_img knn-regression.png%}

ä»ç»“æœå›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œé‡‡ç”¨distanceä½œä¸ºæƒé‡çš„é¢„æµ‹å€¼ï¼Œæ›´ä¸ºå¹³æ»‘ï¼Œä¹Ÿæ›´ä¸ºè´´è¿‘å®é™…å€¼ã€‚

## æ€»ç»“

ç”±äºæœ‰äº†ä¸‰æ–¹åŒ…ï¼Œå…¶å®ä»£ç éƒ½å¾ˆç®€çŸ­ï¼Œä½†æ˜¯æ¯ä¸ªapiéƒ½è¦è‡ªå·±å»çœ‹ä¸€å¤§æ®µè§£é‡Šã€‚å¦å¤–æ·±æ·±æ„Ÿè§‰åˆ°äº†pythonæ“ä½œæ•°ç»„çš„æ–¹ä¾¿ï¼Œå¹¶ä¸”numpyå°è£…åï¼Œç”±äºpythonå…è®¸è¿ç®—ç¬¦é‡è½½ï¼Œæ›´æ˜¯æ„Ÿè§‰è¦ç©å‡ºèŠ±äº†ã€‚æ‰€ä»¥å‡†å¤‡å¼€ä¸€å¸–è®°å½•ä¸‹numpyä¸­ä¸€äº›å‡½æ•°æ¦‚å¿µï¼Œä»¥ä¾¿æŸ¥é˜…ã€‚




[^1]: Irisæ•°æ®é›†æ˜¯å¸¸ç”¨çš„åˆ†ç±»å®éªŒæ•°æ®é›†ï¼Œç”±Fisher, 1936æ”¶é›†æ•´ç†ã€‚Irisä¹Ÿç§°é¸¢å°¾èŠ±å‰æ•°æ®é›†ï¼Œæ˜¯ä¸€ç±»å¤šé‡å˜é‡åˆ†æçš„æ•°æ®é›†ã€‚æ•°æ®é›†åŒ…å«150ä¸ªæ•°æ®é›†ï¼Œåˆ†ä¸º3ç±»ï¼Œæ¯ç±»50ä¸ªæ•°æ®ï¼Œæ¯ä¸ªæ•°æ®åŒ…å«4ä¸ªå±æ€§ã€‚å¯é€šè¿‡èŠ±è¼é•¿åº¦ï¼ŒèŠ±è¼å®½åº¦ï¼ŒèŠ±ç“£é•¿åº¦ï¼ŒèŠ±ç“£å®½åº¦4ä¸ªå±æ€§é¢„æµ‹é¸¢å°¾èŠ±å‰å±äºï¼ˆSetosaï¼ŒVersicolourï¼ŒVirginicaï¼‰ä¸‰ä¸ªç§ç±»ä¸­çš„å“ªä¸€ç±»ã€‚